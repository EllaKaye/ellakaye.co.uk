[
  {
    "objectID": "posts/highlighting-qmd/index.html",
    "href": "posts/highlighting-qmd/index.html",
    "title": "Syntax Highlighting in Quarto",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by-sa/4.0/CitationBibTeX citation:@online{kaye2022,\n  author = {Ella Kaye and Ella Kaye},\n  title = {Syntax {Highlighting} in {Quarto}},\n  date = {2022-07-29},\n  url = {https://ellakaye.rbind.io/posts/highlighting-qmd},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElla Kaye, and Ella Kaye. 2022. “Syntax Highlighting in\nQuarto.” July 29, 2022. https://ellakaye.rbind.io/posts/highlighting-qmd."
  },
  {
    "objectID": "posts/awesome-icon/index.html",
    "href": "posts/awesome-icon/index.html",
    "title": "Awesome Icon",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by-sa/4.0/CitationBibTeX citation:@online{kaye2022,\n  author = {Ella Kaye},\n  title = {Awesome {Icon}},\n  date = {2022-08-05},\n  url = {https://ellakaye.rbind.io/posts/awesome-icon},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElla Kaye. 2022. “Awesome Icon.” August 5, 2022. https://ellakaye.rbind.io/posts/awesome-icon."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html",
    "href": "posts/2021-05-08_welcome-distill/index.html",
    "title": "Welcome to my {distill} website!",
    "section": "",
    "text": "Hello, and welcome to my new site, built using the {distill} package. Here’s why I switched from {blogdown}, and the resources and inspirations that helped me in the process."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#why-distill",
    "href": "posts/2021-05-08_welcome-distill/index.html#why-distill",
    "title": "Welcome to my {distill} website!",
    "section": "Why {distill}?",
    "text": "Why {distill}?\nAs the documentation says, {distill} for R Markdown is a web publishing format optimised for scientific and technical communication. Recent updates to the package, particularly the ability to customise the theme through the create_theme() function, have made it a really appealing choice for those wanting a personalised website based only on R Markdown. The fact that {distill} is made just in R Markdown is a big win for those not wanting to go down (or, like me, looking to get away from), the Hugo route. I’d had a Hugo Academic website for four years, built on {blogdown}, and had been stung a number of times by it breaking after updates to Hugo and Hugo Academic. Last year, I switched to {hugodown}, and that helped, but I had some serious FOMO following that shift after the release of {blogdown} v1.0 a few months later, with all its handy check functions. By then, anyway, I was also displeased with the shift from Hugo Academic to Wowchemy, and getting a little bored of that theme anyway. I had also started seeing more and more {distill} sites pop up from those I admire in the RStats community. I looked into it and and I loved the simplicity of it, both in looks and in management. No more impenetrable file structures! No more not being sure quite why my website is working/looking as it does! Attending Alison Hill’s incredible ‘Crafting Kind Tools’ talk, in which she described the care put into making the {distill} user experience an enjoyable one, was the last push I needed to start my website again (though, to be fair, that talk also described similar care put into the latest release of {blogdown}).\nI’m finding working with {distill} to be an absolute joy!"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#resources",
    "href": "posts/2021-05-08_welcome-distill/index.html#resources",
    "title": "Welcome to my {distill} website!",
    "section": "Resources",
    "text": "Resources\nThis post is not a guide on how to get a {distill} site up an running. There are already great resources for that. In particular, here are the resources I found helpful.\n\nThe basics\n\nThe blogpost from RStudio on (Re-)introducting Distill for R Markdown is a great place to start.\nFor getting up and running, the official {distill} documentation is excellent (and also a {distill} website).\nWhilst we’re on resources from the RStudio team, it’s worth remembering that because {distill} is built on {rmarkdown}, recent developments to that package, such as the ability to style a site with {sass} 1, and developments in {knitr}, such as the ability to easily add alt-text to images, follow through to {distill} too.\nThere’s a great building a blog with distill post from Tom Mock\nAnd one on building a {distill} website from Lisa Lendway\n\n\n\nNext steps\n\nThe {postcards} package from Sean Kross makes it incredibly easy to create simple, stylish, landing pages, and they make great home pages for {distill} sites. Alison Hill has a walk-through on how to set this up: M-F-E-O: postcards + distill\nTom Mock has another excellent {distill} post on including and meta tagging extra content in a distill blog, useful for if/when you want your site to contain content other than distill_articles\nWhilst the create_post() function in {distill} is a great way to get started on a blog post, Eric Ekholm shows how he developed a function wrapped around it to personalise the {distill} template\nFor styling content, John Helveston shows how to customise {distill} with {htmltools} and CSS.\nIf you want to allow readers to comment on your posts, then follow this guide from Vebash Naidoo on how to enable utterances with {distill}"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#inspirationscode",
    "href": "posts/2021-05-08_welcome-distill/index.html#inspirationscode",
    "title": "Welcome to my {distill} website!",
    "section": "Inspirations/Code",
    "text": "Inspirations/Code\nI’m extremely grateful to the authors of the above posts for taking the time to write up what they’ve developed and what they know/have learnt to do, therefore making it easy for others to apply. I guess that’s what blogs are for! But I’ve also learnt a lot from finding sites that I simply like the look of, or have cool features, and looking at the source code on GitHub and adapting it for my own site. Here are some sites that I’ve drawn on for inspiration and code2:\n\n\n\n\nJohn Helveston\n\n\n site  source\nI particularly like his icon_link buttons (as demonstrated just above)3, and the second collection for talks. John tells me he is turn took inspiration for this from Emi Tanaka’s site.\n\nIjeamaka Anyene\n\n\n\n\nIjeamaka has a really cool projects page, where she’s created a card for each project, which I’ve implemented on my site.\n\nTom Mock\n\n\n\n\nCome for the minimalist, stylish design, stay for the fantastic blog content, not just on {distill}, but also on {gt}, R Markdown, #TidyTuesday and much more besides."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#finding-out-more",
    "href": "posts/2021-05-08_welcome-distill/index.html#finding-out-more",
    "title": "Welcome to my {distill} website!",
    "section": "Finding out more",
    "text": "Finding out more\nThe above just scratches the surface. There are many more great sites built on {distill} out there, and lots more ways to customise them. Below are some good ways to find out more.\n\nThe distillery\nThe distillery is a {distill} blog about building {distill} blogs and websites. As the site’s GitHub README states:\n\nThis site was built for the community of distill users to find ways to build and customize their sites and to inspire one another. If you have a distill website or blog, we would love to have it included in the distillery showcasehttps://distillery.rbind.io/showcase.html! Have a post about ways to customize or add new features to your blog? We would love to have it included on the distillery tips & tricks page!\n\nThe showcase is a great place to browse sites for inspiration and the tips and tricks page has loads of great resources (many of which I want to implement on my site in the future, for example Jannick Buhr’s post on making a dark mode for your {distill} site).\n\n\nTwitter\nThere are a number of folk who tweet about {distill} (alongside other #rstats content). I’ve seen useful tweets from Shannon Pileggi @PipingHotData, Lisa Lendway @lisalendway and John Helveston @JohnHelveston. And it pretty much goes without saying that anyone with an interest in {distill} should be following its authors (and general R Markdown gurus), Alison Hill @apreshill, Christophe Dervieux @chrisderv, Rich Iannone @riannone and Yihui Xie @xieyihui (note that the author and original creator of {distill} is JJ Allaire - he does have a twitter account but doesn’t seem to use it)."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#a-sneak-peek-at-distilltools",
    "href": "posts/2021-05-08_welcome-distill/index.html#a-sneak-peek-at-distilltools",
    "title": "Welcome to my {distill} website!",
    "section": "A sneak-peek at {distilltools}",
    "text": "A sneak-peek at {distilltools}\nInspiried by the above-mentioned posts from John Helveston and Eric Ekholm, I’ve started working on a package, {distilltools}, a collection of tools to support the creation and styling of content on websites created using {distill}.\n\n\n\nIt is in the very early stages of development. I am actively seeking contributions - both ideas and code - to help build the package to be broadly useful to a wide variety of {distill} users. The idea is for the package to become a curated, collaborative, community-driven project. Please see the contributing guide for more details on how to get involved. In terms of relationship between packages, I hope in time that {distilltools} can be for {distill} something like what {xaringanExtra} and {xaringanthemer} are for {xaringan}. Some of what I have in mind may sit better within the distill package itself, and I am in touch with the {distill} team about that.\nAt the time of writing, there are just three functions:\n\nicon_link: creates the html for a link button with icon and text (as seen above). Output of icon_link will need styling via the icon-link class to make it look like a button.\ncreate_talk(): a wrapper around distill::create_post() that creates a post in the talk directory and includes buttons (made with icon-link()) for slides (both web and pdf), material, video and project. These can easily be edited in the resulting .Rmd file.\ncreate_post_from_template(): this function operates almost identically to distill::create_post() except for the addition of a path argument, which allows the user to pass in a path to an .Rmd file that can be used as a template for the post. (Note that this function is likely going to be pulled into the {distill} package and hence be depreciated here.)\n\nExpect to hear much more from me, both on this blog and twitter, about {distilltools} in the near future.\nHere’s what my post is about."
  },
  {
    "objectID": "posts/callout-blocks/index.html",
    "href": "posts/callout-blocks/index.html",
    "title": "Testing callout blocks",
    "section": "",
    "text": "See the documentation.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDon’t do that! simple appearance.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDo do this!\n\n\n\n\n\n\n\n\nTip With Caption\n\n\n\nThis is an example of a callout with a caption.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\n\n\n\nDon’t do that! simple appearance.\n\n\n\n\n\n\n\n\n\nDon’t do that! minimal appearance.\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by-sa/4.0/CitationBibTeX citation:@online{kaye,\n  author = {Ella Kaye},\n  title = {Testing Callout Blocks},\n  url = {https://ellakaye.rbind.io/posts/callout-blocks},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElla Kaye. n.d. “Testing Callout Blocks.” https://ellakaye.rbind.io/posts/callout-blocks."
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html",
    "title": "Advent of Code 2020",
    "section": "",
    "text": "Advent of Code is a series of small programming challenges, released daily throughout December in the run-up to Christmas. Part 1 of the challenge is given first. On its successful completion, Part 2 is revealed. The challenges are designed to be solved in any programming language. I will be using R.\nThere will no doubt be a wide variety of ways to solve these problems. I’m going to go with the first thing I think of that gets the right answer. In most cases, I expect that there will be more concise and efficient solutions. Most of the time I’m working in R, it’s within the tidyverse, so I imagine that framework will feature heavily below.\nEach participant gets different input data, so my numerical solutions may be different from others. If you’re not signed up for Advent of Code yourself, but want to follow along with my data, you can download it at from the data links at the beginning of each day’s section. The links in the day section headers take you to challenge on the Advent of Code page."
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-1-report-repair",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-1-report-repair",
    "title": "Advent of Code 2020",
    "section": "Day 1: Report Repair",
    "text": "Day 1: Report Repair\n\n\n\nMy day 1 data\n\nPart 1: Two numbers\nThe challenge is to find two numbers from a list that sum to 2020, then to report their product.\nexpand.grid() creates a data frame from all combinations of the supplied vectors. Since the vectors are the same, each pair is duplicated. In this case the two numbers in the list that sum to 2020 are 704 and 1316, and we have one row with 704 as Var1 and one with 704 as Var2. slice(1) takes the first occurrence of the pair.\n\n\nToggle the code\nlibrary(dplyr)\n\nexpenses <- readLines(\"data/AoC_day1.txt\") %>%\n  as.numeric()\n\nexpand.grid(expenses, expenses) %>% \n  mutate(sum = Var1 + Var2) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 926464\n\n\n\n\nPart 2: Three numbers\nThe follow-up challenge is the same but with three numbers. I went with essentially the same code but it’s notably slower. There are a lot of repeated calculations here: each triplet appears six times in the table.\n\n\nToggle the code\nexpand.grid(expenses, expenses, expenses) %>% \n  mutate(sum = Var1 + Var2 + Var3) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2 * Var3) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 65656536"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-2-password-philosophy",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-2-password-philosophy",
    "title": "Advent of Code 2020",
    "section": "Day 2: Password Philosophy",
    "text": "Day 2: Password Philosophy\nMy day 2 data\n\nPart 1: Number of letters\nWe need to find how many passwords are valid according to their policy. The policies and passwords are given as follows:\n1-3 a: abcde\n1-3 b: cdefg\n2-9 c: ccccccccc\nEach line gives the password policy and then the password. The password policy indicates the lowest and highest number of times a given letter must appear for the password to be valid. For example, 1-3 a means that the password must contain a at least 1 time and at most 3 times.\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\nFirst load the libraries we’ll need. We then read in the data and use tidyr functions to separate out the parts of the policy and the password, making sure to convert the columns to numeric as appropriate:\n\n\nToggle the code\npasswords <- readr::read_tsv(\"data/AoC_day2.txt\", col_names = FALSE) %>%\n  separate(X1, c(\"policy\", \"password\"), sep = \":\") %>%\n  separate(policy, c(\"count\", \"letter\"), sep = \" \") %>%\n  separate(count, c(\"min\", \"max\")) %>%\n  mutate(min = as.integer(min),\n         max = as.integer(max))\n\n\nNext, we use the stringr function str_count() to count how many times the given letter appears in the password, and conditional logic to check whether it is repeated within the specified number of times. Because TRUE has a numeric value of 1 and FALSE has a numeric value of 0, we can sum the resulting column to get a count of how many passwords are valid according to their policies.\n\n\nToggle the code\npasswords %>%\n  mutate(count = str_count(password, letter)) %>%\n  mutate(password_in_policy = if_else(count >= min & count <= max, TRUE, FALSE)) %>%\n  summarise(correct = sum(password_in_policy)) %>%\n  pull(correct)\n\n\n[1] 625\n\n\n\n\nPart 2: Position of letters\nNow the policy is interpreted differently. Each policy actually describes two positions in the password, where 1 means the first character, 2 means the second character, and so on. Exactly one of these positions must contain the given letter. How many are valid now?\nThere were a couple of gotchas here. When I used separate() in the previous part, I had inadvertently left a leading whitespace in front of the password, something that was messing up my indexing with str_sub. Using str_trim() first cleared that up. Also, we need exactly one of the positions to match. | is an inclusive or. We need xor() for exclusive or instead.\n\n\nToggle the code\npasswords %>%\n  mutate(password = str_trim(password)) %>%\n  mutate(pos1_letter = str_sub(password, min, min),\n         pos2_letter = str_sub(password, max, max)) %>%\n  mutate(match_one = xor(pos1_letter == letter, pos2_letter == letter)) %>%\n  summarise(correct = sum(match_one)) %>%\n  pull(correct) \n\n\n[1] 391"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-3-toboggan-trajectory",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-3-toboggan-trajectory",
    "title": "Advent of Code 2020",
    "section": "Day 3: Toboggan Trajectory",
    "text": "Day 3: Toboggan Trajectory\nMy day 3 data\n\nPart 1: Encountering trees\nStarting at the top left corner of the map, how many trees (“#”) do we encounter, going at a trajectory of 3 right and 1 down?\nFirst, read in the data and save it into a matrix. My method here feels really hack-y. I’m sure there must be a better approach.\n\n\nToggle the code\nlibrary(dplyr)\n\ntree_map <- readr::read_tsv(\"data/AoC_day3.txt\", col_names = FALSE)\n\nnum_col <- tree_map %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\ntree_vec <- tree_map %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\ntree_mat <- matrix(tree_vec, ncol = num_col, byrow = TRUE)\n\n\nNow work my way across and down the matrix, using the %% modulo operator to loop round where necessary. The -1 and +1 in the line ((y + right - 1) %% num_col) + 1 is a hack to get round the fact that, for num_col columns, the modulo runs from 0 to num_col - 1, but the column indexes for our matrix run from 1 to num_col.\n\n\nToggle the code\nright <- 3\ndown <- 1\n\nnum_rows <- nrow(tree_mat)\nnum_col <- ncol(tree_mat)\n\n# start counting trees encountered\ntrees <- 0\n\n# start square\nx <- 1\ny <- 1\n  \nwhile (x <= num_rows) {\n  \n  # cat(\"row: \", x, \"col: \", y, \"\\n\")\n  \n  if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n  x <- x + down\n  y <- ((y + right - 1) %% num_col) + 1\n  \n}\n\ntrees\n\n\n[1] 299\n\n\n\n\nPart 2: Checking further slopes\nWe now need to check several other trajectories, and multiply together the number of trees we find, so we wrap the Part 1 code into a function.\n\n\nToggle the code\nslope_check <- function(tree_mat, right, down) {\n  \n  num_rows <- nrow(tree_mat)\n  num_col <- ncol(tree_mat)\n\n  # start counting trees encountered\n  trees <- 0\n\n  # start square\n  x <- 1\n  y <- 1\n  \n  while (x <= num_rows) {\n  \n    if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n    x <- x + down\n    y <- ((y + right - 1) %% num_col) + 1\n  \n  }\n  trees\n}\n\nprod(slope_check(tree_mat, 1, 1),\n     slope_check(tree_mat, 3, 1),\n     slope_check(tree_mat, 5, 1),\n     slope_check(tree_mat, 7, 1),\n     slope_check(tree_mat, 1, 2))\n\n\n[1] 3621285278"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-4-passport-processing",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-4-passport-processing",
    "title": "Advent of Code 2020",
    "section": "Day 4: Passport Processing",
    "text": "Day 4: Passport Processing\n\n\n\nMy day 4 data\n\nPart 1: Complete passports\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\n\n\nUsing readr::read_tsv() off the bat removes the blank lines, making it impossible to identify the different passports, but reading in the data via readLines() then converting as_tibble() preserves them, and then allows us to use tidyverse functions for the remaining tidying. cumsum() on a logical vectors takes advantage of FALSE having a numeric value of zero and TRUE having a numeric value of one.\n\n\nToggle the code\npassports <- readLines(\"data/AoC_day4.txt\") %>%\n  as_tibble() %>%\n  separate_rows(value, sep = \" \") %>%\n  mutate(new_passport = value == \"\") %>%\n  mutate(ID = cumsum(new_passport) + 1) %>%\n  filter(!new_passport) %>%\n  select(-new_passport) %>%\n  separate(value, c(\"key\", \"value\"), sep = \":\") %>%\n  relocate(ID)\n\n\nOur data is now in three columns, with ID, key and value, so now we need to find the number of passports with all seven fields once cid is excluded:\n\n\nToggle the code\npassports %>%\n  filter(key != \"cid\") %>%\n  count(ID) %>%\n  filter(n == 7) %>%\n  nrow()\n\n\n[1] 210\n\n\n\n\nPart 2: Valid passports\nNow we need to add data validation checks:\n\nbyr (Birth Year) - four digits; at least 1920 and at most 2002.\niyr (Issue Year) - four digits; at least 2010 and at most 2020.\neyr (Expiration Year) - four digits; at least 2020 and at most 2030.\nhgt (Height) - a number followed by either cm or in:\n\nIf cm, the number must be at least 150 and at most 193.\nIf in, the number must be at least 59 and at most 76.\n\nhcl (Hair Color) - a # followed by exactly six characters 0-9 or a-f.\necl (Eye Color) - exactly one of: amb blu brn gry grn hzl oth.\npid (Passport ID) - a nine-digit number, including leading zeroes.\ncid (Country ID) - ignored, missing or not.\n\nIgnoring the cid field, we narrow down on passports that at least have the right number of fields, and extract the number from the hgt column:\n\n\nToggle the code\ncomplete_passports <- passports %>%\n  filter(key != \"cid\") %>%\n  add_count(ID) %>%\n  filter(n == 7) %>%\n  select(-n) %>%\n  mutate(hgt_value = case_when(\n    key == \"hgt\" ~ readr::parse_number(value),\n    TRUE ~ NA_real_)) %>%\n  ungroup()\n\n\nThen we create a check column, which is TRUE when the value for each key meets the required conditions. Those with 7 TRUEs are valid. Note that with case_when() we’ve left the check column as NA when the condition is FALSE, requiring na.rm = TRUE in the call to sum(). We can get round that by adding a final line to the case_when() condition stating TRUE ~ FALSE. TRUE here is a catch-all for all remaining rows not covered by the conditions above, and then we set them to FALSE, but I find the line TRUE ~ FALSE unintuitive.\n\n\nToggle the code\ncomplete_passports %>%\n  mutate(check = case_when(\n    (key == \"byr\" & value >= 1920) & (key == \"byr\" & value <= 2002) ~ TRUE,\n    (key == \"iyr\" & value >= 2010) & (key == \"iyr\" & value <= 2020) ~ TRUE,\n    (key == \"eyr\" & value >= 2020) & (key == \"eyr\" & value <= 2030) ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"cm\") & hgt_value >= 150 & hgt_value <= 193 ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"in\") & hgt_value >= 59 & hgt_value <= 76 ~ TRUE,  \n    key == \"hcl\" & str_detect(value, \"^#[a-f0-9]{6}$\") ~ TRUE,\n    key == \"ecl\" & value %in% c(\"amb\", \"blu\", \"brn\", \"gry\", \"grn\", \"hzl\", \"oth\") ~ TRUE,\n    key == \"pid\" & str_detect(value, \"^[0-9]{9}$\") ~ TRUE\n  )) %>%\n  group_by(ID) %>%\n  summarise(check_all = sum(check, na.rm = TRUE)) %>%\n  filter(check_all == 7) %>%\n  nrow()\n\n\n[1] 131"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-5-binary-boarding",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-5-binary-boarding",
    "title": "Advent of Code 2020",
    "section": "Day 5: Binary Boarding",
    "text": "Day 5: Binary Boarding\nMy day 5 data\n\nPart 1: Finding all seat IDs\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(stringr)\n\n\nThe code below sets starts by setting each row number to 127 and each column number to 7, the maximum they can be, then, working along the string, lowering the maximum (or leaving it as is) one letter at a time:\n\n\nToggle the code\nboarding <- readr::read_tsv(\"data/AoC_day5.txt\", col_names = FALSE) %>%\n  rename(binary = X1)\n\nseat_IDs <- boarding %>%\n  mutate(row = 127) %>%\n  mutate(col = 7) %>%\n  mutate(row = if_else(str_sub(binary, 1, 1) == \"F\", row - 64, row)) %>%\n  mutate(row = if_else(str_sub(binary, 2, 2) == \"F\", row - 32, row)) %>%\n  mutate(row = if_else(str_sub(binary, 3, 3) == \"F\", row - 16, row)) %>%\n  mutate(row = if_else(str_sub(binary, 4, 4) == \"F\", row - 8, row)) %>%\n  mutate(row = if_else(str_sub(binary, 5, 5) == \"F\", row - 4, row)) %>%\n  mutate(row = if_else(str_sub(binary, 6, 6) == \"F\", row - 2, row)) %>%\n  mutate(row = if_else(str_sub(binary, 7, 7) == \"F\", row - 1, row)) %>%\n  mutate(col = if_else(str_sub(binary, 8, 8) == \"L\", col - 4, col)) %>%\n  mutate(col = if_else(str_sub(binary, 9, 9) == \"L\", col - 2, col)) %>%  \n  mutate(col = if_else(str_sub(binary, 10, 10) == \"L\", col - 1, col)) %>%  \n  mutate(ID = row * 8 + col) \n\nseat_IDs %>%\n  summarise(max = max(ID)) %>%\n  pull(max)\n\n\n[1] 963\n\n\nOK, I know I said in the introduction to this post that I would go with the first solution I think of that gets the right answer, and the above does work, but I’m deeply unhappy with the code. There’s too much repetition, I don’t like the use of subtraction when diving by 2 feels more appropriate in a binary context, and it doesn’t feel like I’ve taken full advantage of the mathematical structure of the problem. So, on further reflection, I realise that the way that ID is defined is essentially turning a binary number into a decimal, where we get the binary number as a string by replacing “B” and “R” by “1” and L” and “F” by “0”. Then, I just found, there is a base R function strtoi() that takes a string of digits in a given base and converts it to a base 10 integer, just what we need:\n\n\nToggle the code\nseat_IDs <- boarding %>%\n  mutate(binary = str_replace_all(binary, \"L|F\", \"0\")) %>%\n  mutate(binary = str_replace_all(binary, \"B|R\", \"1\")) %>%\n  mutate(ID = strtoi(binary, base = 2)) %>%\n  arrange(desc(ID))\n\nseat_IDs %>%\n  slice(1) %>%\n  pull(ID)\n\n\n[1] 963\n\n\nThat’s better!\n\n\nPart 2: Finding my seat ID\nWe need to find the missing number, so we arrange the IDs in ascending order and look at the gap between each ID and the preceding one. In most cases, that should be one. Where we have a gap of 2, we must have skipped the integer below:\n\n\nToggle the code\nseat_IDs %>%\n  arrange(ID) %>%\n  mutate(diff = lag(ID)) %>%\n  mutate(gap = ID - diff) %>% \n  filter(gap == 2) %>%\n  summarise(my_seat = ID - 1) %>%\n  pull(my_seat)\n\n\n[1] 592"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-6-custom-customs",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-6-custom-customs",
    "title": "Advent of Code 2020",
    "section": "Day 6: Custom Customs",
    "text": "Day 6: Custom Customs\nMy day 6 data\n\nPart 1: Anyone answers\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\nWithin each group, we need to find the number of unique letters within each group. We read in and separate the data using the tricks learnt for Day 4, and take advantage of the rowwise() feature in dplyr 1.0.0.\n\n\nToggle the code\ncustoms_groups <- readLines(\"data/AoC_day6.txt\") %>%\n  as_tibble() %>%\n  mutate(new_group = value == \"\") %>%\n  mutate(group_ID = cumsum(new_group) + 1) %>%\n  filter(!new_group) %>%\n  select(-new_group) %>%\n  group_by(group_ID) \n\ncustoms_groups %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(qsu = list(unique(qss))) %>%\n  mutate(count = length(qsu)) %>%\n  ungroup() %>%\n  summarise(total = sum(count)) %>%\n  pull(total)\n\n\n[1] 6585\n\n\n\n\nPart 2: Everyone answers\nNow, instead of unique letters in a group, we need to find the number of letters which appear in all the answers for everyone in the same group. I first note how many people are in each group, then tabulate the number of occurrences of each letter in the group, then count (by summing a logical vector) the number of matches between occurrences of letter and the number in group. Finally, we sum across all groups.\n\n\nToggle the code\ncustoms_groups %>%  \n  add_count(group_ID, name = \"num_in_group\") %>%\n  group_by(group_ID, num_in_group) %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(letter_table = list(table(qss))) %>%\n  slice(1) %>%\n  mutate(in_common = sum(num_in_group == letter_table)) %>%\n  ungroup() %>%\n  summarise(total = sum(in_common)) %>%\n  pull(total)\n\n\n[1] 3276"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-7-handy-haverstocks",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-7-handy-haverstocks",
    "title": "Advent of Code 2020",
    "section": "Day 7: Handy Haverstocks",
    "text": "Day 7: Handy Haverstocks\nMy day 7 data\n\nPart 1: Number of colour bags\n\n\nToggle the code\nlibrary(tidyverse)\n\n\nWe have colour-coded bags that must contain a specific number of other colour-coded bags.\n\n\nToggle the code\nbags <- read_tsv(\"data/AoC_day7.txt\", col_names = FALSE)\n\nhead(bags)\n\n\n# A tibble: 6 × 1\n  X1                                                                            \n  <chr>                                                                         \n1 wavy bronze bags contain 5 striped gold bags, 5 light tomato bags.            \n2 drab indigo bags contain 4 pale bronze bags, 2 mirrored lavender bags.        \n3 pale olive bags contain 3 faded bronze bags, 5 wavy orange bags, 3 clear blac…\n4 faded white bags contain 5 vibrant violet bags, 4 light teal bags.            \n5 mirrored magenta bags contain 2 muted cyan bags, 3 vibrant crimson bags.      \n6 dull purple bags contain 1 striped fuchsia bag.                               \n\n\nOur first task is to parse the natural language and split the rules into one container/contains pair per line:\n\n\nToggle the code\nrules <- bags %>%\n  mutate(rule = row_number()) %>%\n  separate(X1, c(\"container\", \"contains\"), sep = \" bags contain \") %>%\n  separate_rows(contains, sep = \",\") %>%\n  mutate(contains = str_remove(contains, \"\\\\.\")) %>%\n  mutate(contains = str_remove(contains, \"bags|bag\")) %>%\n  #mutate(contains = str_replace(contains, \"no other\", \"0 other\")) %>%\n  extract(contains, c('number', 'contains'), \"(\\\\d+) (.+)\") %>%\n  filter(!is.na(number)) %>%\n  mutate(contains = str_trim(contains)) %>%\n  mutate(number = as.integer(number)) \n\n\nTo find all bags that con eventually contain our shiny gold bag, we first find the bags that can contain it directly. We then find the bags that can contain those bags and take the union of the two levels. We repeat, stopping when going up a level adds no further bags to the vector of bag colours already found. We then subtract 1, because we don’t want to count the original shiny gold bag.\n\n\nToggle the code\n# function to find all colours that contain a vector of other colours:\ncontains_colours <- function(colours) {\n  rules %>%\n    filter(contains %in% colours) %>%\n    distinct(container) %>%\n    pull(container)\n}\n\nbags <- \"shiny gold\"\nold_length <- length(bags)\nnew_length <- 0\n\n# keeping adding to the vector of bags, until no change\nwhile(old_length != new_length) {\n  old_length = length(bags)\n  bags <- base::union(bags, contains_colours(bags)) %>% unique()\n  new_length <- length(bags)\n  #cat(old_length, \", \", new_length, \"\\n\")\n}\n\nlength(bags) - 1\n\n\n[1] 274\n\n\n\n\nPart 2: Number of bags\nNow we need to discover the number of bags that a shiny gold bag must contain. I figured that lends itself to recursion, but struggled on the details. Hat tip to David Robinson for this solution. I’ve learnt a lot for myself by unpicking how it works.\n\n\nToggle the code\ncount_all_contained <- function(colour) {\n  \n  relevant_rules <- rules %>%\n    filter(container %in% colour)\n  \n  sum(relevant_rules$number * (1 + map_dbl(relevant_rules$contains, count_all_contained)))\n  \n}\n\ncount_all_contained(\"shiny gold\")\n\n\n[1] 158730"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-8-handheld-halting",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-8-handheld-halting",
    "title": "Advent of Code 2020",
    "section": "Day 8: Handheld Halting",
    "text": "Day 8: Handheld Halting\nMy day 8 data\n\nPart 1: Infinite Loop\nOur programme gets stuck in an infinite loop. As well as keeping track of the accumulator, we need to keep track of where we’ve visited, and stop when we visit the same instruction twice. We use a data.frame() rather than a tibble() as the former is easier to index into.\n\n\nToggle the code\ninstructions <- \n  read.table(\"data/AoC_day8.txt\", col.names = c(\"instruction\", \"value\"))\n\n\nWe start with a pretty straight-forward loop, noting that at most it can run for one more than the number of instructions in the programme until it hits an instruction it’s already visited. We update row number to visit next and the accumulator as appropriate.\n\n\nToggle the code\ninstructions$visited <- 0\n\nrow <- 1\naccumulator <- 0\n\nnum_rows <- nrow(instructions)\n\nfor (i in 1:(num_rows+1)) {\n\n  if (instructions[row, \"visited\"] != 0) break\n  \n  # +1 on number of times the row is visited\n  instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n\n  # case when the instruction is \"acc\"\n  if (instructions[row, \"instruction\"] == \"acc\") {\n    accumulator <- accumulator + instructions[row, \"value\"]\n    row <- row + 1\n  }\n  \n  # case when the instruction is \"jmp\"\n  else if (instructions[row, \"instruction\"] == \"jmp\") {\n    row <- row + instructions[row, \"value\"]\n  }\n\n  # case when the instruction is \"nop\"\n  else if (instructions[row, \"instruction\"] == \"nop\") {\n    row <- row + 1\n  }\n}\n  \naccumulator\n\n\n[1] 1915\n\n\n\n\nPart 2: Fixing the programme\nTo break the loop, one of the nop instructions in the programme should be a jmp or vice versa. The plan is to swap these out one by one and check if the programme completes. It’s not a sophisticated approach, but it works fast enough (about a second).\nFirst we note that the broken instruction must be one that we visited in Part 1. Also, an instruction of jmp with a value of 0 will get us stuck in a one-line infinite loop, so we avoid that.\n\n\nToggle the code\nlibrary(dplyr)\n\nrows_to_check <- instructions %>%\n  mutate(row_id = row_number()) %>%\n  filter(visited != 0) %>%\n  filter(instruction != \"acc\") %>%\n  filter(!(instruction == \"nop\" & value == 0)) %>%\n  pull(row_id)\n\n\nWe have 93 instruction to check. We modify our code from Part 1 slightly, converting it into a function and returning a list with values completes and accumulator. completes is FALSE as soon as we visit a row twice and TRUE if the number of our next row to visit is greater than the number of rows in the programme.\n\n\nToggle the code\nprogramme_completes <- function(instructions) {\n  \n  row <- 1L\n  accumulator <- 0\n  \n  num_rows <- nrow(instructions)\n  \n  for (i in 1:(num_rows+1)) {\n  \n    if (instructions[row, \"visited\"] != 0) {\n      return(list(completes = FALSE, accumulator = accumulator)) \n    }\n    \n    # +1 on number of times the row is visited\n    instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n  \n    # case when the instruction is \"acc\"\n    if (instructions[row, \"instruction\"] == \"acc\") {\n      accumulator <- accumulator + instructions[row, \"value\"]\n      row <- row + 1\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"jmp\") {\n      row <- row + instructions[row, \"value\"]\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"nop\") {\n      row <- row + 1\n    }\n  \n    if (row > num_rows) {\n      return(list(completes = TRUE, accumulator = accumulator)) \n    }\n  }\n}  \n\n\nWe now loop over the rows we’ve identified to check, breaking the loop as soon as we find a programme that completes. Finally, we extract the accumulator value from the successful programme.\n\n\nToggle the code\ninstructions$visited <- 0\n\nfor (row in rows_to_check) {\n  \n  # modify one row of the instructions,\n  # copying data frame so we don't have to modify it back\n  modified_instructions <- instructions\n  \n  ifelse(instructions[row, 1] == \"jmp\", \n         modified_instructions[row, 1] <- \"nop\", \n         modified_instructions[row, 1] <- \"jmp\") \n  \n  # check if the modified programme completes\n  check_programme <- programme_completes(modified_instructions)\n  \n  if (check_programme$completes) \n    break\n}\n\ncheck_programme$accumulator\n\n\n[1] 944"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-9-encoding-error",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-9-encoding-error",
    "title": "Advent of Code 2020",
    "section": "Day 9: Encoding Error",
    "text": "Day 9: Encoding Error\nMy day 9 data\n\nPart 1: Weak Link\nWe have to find the first number in the list which is not the sum of a pair of different numbers in the preceding 25 numbers.\n\n\nToggle the code\ninput <- as.double(readLines(\"data/AoC_day9.txt\")) \n\n\nThere’s a nice trick for finding the pair of numbers in a vector that sum to a target that was doing the rounds on twitter in response to the Day 1 challenge: intersect(input, 2020 - input). For this challenge, we expand on that idea, writing it as a check_sum function. Where there’s more than one pair, it won’t say which pair together, and if the number that’s half the target appears in the addends, it will only appear once in the output. However, for this challenge, we only need to know when there are no pairs that sum to the target, which will be the case when the length of the output of check_sum is 0.\n\n\nToggle the code\ncheck_sum <- function(target, addends) {\n  intersect(addends, target-addends)\n}\n\n\nThen, it’s simply a case of iterating over windows of length 25, checking whether the following number is the sum of a distinct pair in that window, and returning the first one that isn’t.\n\n\nToggle the code\nfind_invalid_num <- function(vec, win = 25) {\n  \n  for (i in (win+1):length(vec)) {\n    check <- check_sum(vec[i], vec[(i-win):(i-1)])\n    \n    if (length(check) == 0) return(vec[i])\n  }\n  \n}\n\nfind_invalid_num(input)\n\n\n[1] 507622668\n\n\n\n\nPart 2: Contiguous set\nFind a contiguous set in the list that sums to the invalid number from Part 1, and add together the largest and smallest number in that range.\nFirst, we note that after a certain point, all numbers in the input are larger than the target, so we don’t need to consider those. We reduce our input vector accordingly.\n\n\nToggle the code\ntarget <- find_invalid_num(input)\n\ninput_reduced <- input[1:(max(which(input <= target)))]\n\n\nTo find the contiguous set in the list that sums to the target, we make use of accumulate() from the purrr package. Let the input list be \\(x = (x_1, x_2,..., x_n)\\). Then accumulate(x, sum) returns \\(a = (x_1, x_1 + x_2,..., \\sum_{j=1}^n x_j)\\). We check whether any element of this vector is equal to the target. If so we index into the input vector appropriately, sum the min and max in the range and we’re done. If not, we consider the sums of all windows starting with the second element of the input list, and so on.\n\n\nToggle the code\ncontiguous_sum <- function(input, target) {\n  \n  len <- length(input)\n  \n  for (i in 1:len) {\n    a <- purrr::accumulate(input[i:len], sum)\n    b <- a == target\n    \n    if (sum(b) == 1) {\n      output_length <- which(b)\n      \n      contiguous_set <- input[i:(i + output_length - 1)]\n      \n      return(sum(range(contiguous_set)))\n    }\n  }\n}\n\ncontiguous_sum(input_reduced, target)\n\n\n[1] 76688505\n\n\nI appreciate that there’s some redundant calculation in this method. The vectors of accumulated sums can contain numbers larger than the target (if writing our own loop, we could break as soon as the accumulated sum got too big). Also, in retrospect, we could have only run accumulate once, then in the second iteration of the loop, subtracted input[1] from the result, in the third iteration subtracted input[2] from that result, etc. However, the function as written is concise and easy to understand, and gets our answer in around a second, so that will do!"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-10-adapter-array",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-10-adapter-array",
    "title": "Advent of Code 2020",
    "section": "Day 10: Adapter Array",
    "text": "Day 10: Adapter Array\nMy day 10 data\n\nPart 1: Adapter Distribution\nThis is simply a case of ordering the adapters, prepending 0 and appending the the max in the list plus three, then finding the differences.\n\n\nToggle the code\nlibrary(dplyr)\n\n\n\n\nToggle the code\nadapters <- \n  readLines(\"data/AoC_day10.txt\") %>%\n  as.integer()\n\nadapter_diffs <- c(adapters, 0, max(adapters) + 3) %>% \n  sort() %>%\n  diff()\n\nsum(adapter_diffs == 1) * sum(adapter_diffs == 3)\n\n\n[1] 3034\n\n\n\n\nPart 2: Adapter combinations\nInstead of building up sequences of adapters, we see what we can remove from the full list.\nFirst, we check the diffs: are they just 1 and 3 or are there any 2s?\n\n\nToggle the code\ntable(adapter_diffs)\n\n\nadapter_diffs\n 1  3 \n74 41 \n\n\nWe can’t remove an adapter if its difference with the previous adapter is 3, otherwise the difference between the adapters on either side of it will be too big.\nWhat about diffs of 1? It depends how many ones there are around it. We can check this using the rle() (run length encoding) function\n\n\nToggle the code\nruns <- rle(adapter_diffs)\nruns\n\n\nRun Length Encoding\n  lengths: int [1:48] 3 2 4 2 4 2 4 1 4 2 ...\n  values : num [1:48] 1 3 1 3 1 3 1 3 1 3 ...\n\n\nWhat is the distribution of lengths of sequences of 1s?\n\n\nToggle the code\nruns_table <- table(runs$lengths) \nruns_table\n\n\n\n 1  2  3  4 \n13 14 10 11 \n\n\nWe have at most four diffs of 1 in a row.\nWe need to check that if we remove an adapter, the new differences do not exceed 3. Example sequences really helped me figure out what’s going on here:\n\nIf the diff sequence is …, 3, 1, 3,… (e.g. adapters 1, 4, 5, 8)\n\n1 option to keep as is\nWe cannot remove any adapters\n1 option in total\n\nIf the diff sequence is …, 3, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 9)\n\n1 option to keep as is\n1 option to remove one adapter (e.g. the 5)\nwe cannot remove two adapters\n2 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 10)\n\n1 option to keep as is\n2 options to remove one adapter (e.g. the 5 or 6)\n1 options to remove two adapters (e.g. the 5 and 6)\nWe cannot remove three adapters\n4 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 8, 11)\n\n1 option to keep as is\n3 options to remove one adapter (e.g. 5, 6, or 7)\n3 options to remove two adapters (e.g. any two of 5, 6, and 7)\nWe cannot remove three adapters\n7 options total\n\n\nFinally, we multiply each run length of difference of 1s with the number of options we have for removing adapters, then take the product of those products.\n\n\nToggle the code\nruns_df <- tibble(lengths = runs$lengths, values = runs$values)\n\noptions <- tibble(lengths = c(1,2,3,4), options = c(1,2,4,7))\n\nruns_df %>%\n  filter(values == 1) %>%\n  left_join(options, by = \"lengths\") %>%\n  summarise(prod_options = prod(options)) %>%\n  pull(prod_options) %>%\n  format(scientific = FALSE) \n\n\n[1] \"259172170858496\""
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-11-seating-system",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-11-seating-system",
    "title": "Advent of Code 2020",
    "section": "Day 11: Seating System",
    "text": "Day 11: Seating System\nMy day 11 data\n\nPart 1: Changing layout\nMy code for Day 11 runs a little slow (about 10 seconds for Part 1 and 80 seconds for Part 2), so for the sake of being able to rebuild this page quickly as I keep updating it working through the challenges, I will demonstrate this code with the test input provided as an example.\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\n\n\nFirst we read in the data and convert it to a matrix (using the datapasta package for the test input):\n\n\nToggle the code\n# layout <- readr::read_tsv(\"data/AoC_day11.txt\", col_names = FALSE)\n\nlayout <- tibble::tribble(\n  ~X1,\n  \"L.LL.LL.LL\",\n  \"LLLLLLL.LL\",\n  \"L.L.L..L..\",\n  \"LLLL.LL.LL\",\n  \"L.LL.LL.LL\",\n  \"L.LLLLL.LL\",\n  \"..L.L.....\",\n  \"LLLLLLLLLL\",\n  \"L.LLLLLL.L\",\n  \"L.LLLLL.LL\"\n  )\n\n\n\n\nToggle the code\n# get number of columns for matrix\nnum_col <- layout %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\n# split layout into characters and turn to vector\nlayout_vec <- layout %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\n# organise into matrix\ninitial_layout <- matrix(layout_vec, ncol = num_col, byrow = TRUE)\n\n\nNext, we write a helper function that, given a matrix and row and column indices, returns a vector of the adjacent seats. We need to take care when indexing into the matrix, so we treat all corner and edge cases separately. Fiddly, but gets the job done.\n\n\nToggle the code\nget_adj <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # corner cases\n  if (i == 1 & j == 1) {adj <- c(mat[1,2], mat[2,1:2])}\n  else if (i == 1 & j == nc) {adj <- c(mat[1,(nc-1)], mat[2,(nc-1):nc])}\n  else if (i == nr & j == 1) {adj <- c(mat[nr,2], mat[nr-1,1:2])}\n  else if (i == nr & j == nc) {adj <- c(mat[nr-1, (nc-1):nc], mat[nr, nc-1])}  \n  \n  # edge cases\n  else if (i == 1) {adj <- c(mat[1, c(j-1,j+1)], mat[2, (j-1):(j+1)])}\n  else if (i == nr) {adj <- c(mat[nr, c(j-1,j+1)], mat[nr-1, (j-1):(j+1)])}\n  else if (j == 1) {adj <- c(mat[c(i-1, i+1), 1], mat[(i-1):(i+1), 2])}\n  else if (j == nc) {adj <- c(mat[c(i-1, i+1), nc], mat[(i-1):(i+1), nc-1])}\n  \n  # inside cases\n  else {adj <- c(mat[i-1,(j-1):(j+1)], mat[i,c(j-1,j+1)], mat[i+1,(j-1):(j+1)])}\n  \n  adj\n}\n\n\nOnce we have a vector of surrounding seats, we can apply the rules in the problem to determine whether a given seat needs to change state. The needs_changing helper function does that. It’s overkill at this point to give options to specify the function for finding the vector of seats to check, and the maximum number of occupied seats people can tolerate around them, but (spolier alert) I put in these options when working on the challenge in Part 2.\n\n\nToggle the code\nneeds_changing <- \n  function(mat, i,j, get_surround = get_adj, max_occupied = 4) {\n  \n  surround <- get_surround(mat, i,j)\n  n_occupied <- sum(surround == \"#\")\n  \n  if ((mat[i,j] == \"L\") & (n_occupied == 0)) return(TRUE)\n  \n  else if ((mat[i,j] == \"#\") & (n_occupied >= max_occupied)) {\n    return(TRUE)\n  }\n  \n  else return(FALSE)\n}\n\n\nSince floor spaces don’t change, we only need to consider seats. We save the indices of the seats into a data frame, so we can vectorise over it using tidyverse functions. However, when we’ve determined the seats that need changing, using our needs_changing function, we need to convert those indices from a data.frame into a matrix, in order to index into the layout matrix appropriately and make the changes.\n\n\nToggle the code\nseats <- which(initial_layout != \".\", arr.ind = TRUE)\n\nseats_df <- as.data.frame(seats) %>%\n  rename(i = row, \n         j = col)\n\n\n\n\nToggle the code\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_1_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 37\n\n\nOn the test set, this takes 5 iterations. On the full data set, my answer is 2316, and it took 107 iterations.\n\n\nPart 2: Looking further\nNow, people look to the first seat they can see in each direction, and will change from occupied to unoccupied if five or more of them are occupied.\nThe plan is to write a function that extracts full vectors from a given seat to the edge of the layout matrix in each of the eight directions, then finds the first seat in each of those directions, and finally collects those into a vector of the seats under consideration when determining if a change is needed. Then I can reuse the loop from Part 1, just changing the arguments in the calls to needs_changing.\nHere’s a helper function to get the first seat in a vector looking in one direction:\n\n\nToggle the code\nget_first_seat_from_vec <- function(vec) {\n  \n  if (any(vec %in% c(\"#\", \"L\"))) {\n    return(vec[min(which(vec != \".\"))])\n  }\n  \n  return(NA)\n}\n\n\nNow, if I thought getting adjacent seats to a given seat in Part 1 was fiddly, it’s nothing on getting a vector from a given seat to the edge of the matrix. There are many cases to consider to make we we don’t go out of bounds. In the diagonal directions, first we get a matrix of the indices of the matrix we need, then subset into the matrix accordingly.\n\n\nToggle the code\n# takes a layout matrix (elements \".\", \"#\", \"L\")\n# returns vector with first \"L\" or \"#\" encountered in each direction\nget_first_seat <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # North\n  if (i == 1) N <- NA\n  if (i > 1) N <- mat[(i-1):1,j]\n  \n  # South\n  if (i == nr) S <- NA\n  if (i < nr) S <- mat[(i+1):nr,j]\n  \n  # East\n  if (j == nc) E <- NA\n  if (j < nc) E <- mat[i, (j+1):nc]\n  \n  # West\n  if (j == 1) W <- NA\n  if (j > 1) W <- mat[i, (j-1):1]\n  \n  # how far in each direction to edge of matrix\n  to_N <- i - 1\n  to_S <- nr - i\n  to_E <- nc - j\n  to_W <- j - 1\n  \n  # North-West\n  NW_length <- min(to_N, to_W)\n  \n  if (i == 1 | j == 1) NW <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NW_length), (j-1):(j-NW_length)), ncol = 2)\n    NW <- mat[mat_index]\n  }\n  \n  # North-East\n  NE_length <- min(to_N, to_E)\n  \n  if (i == 1 | j == nc) NE <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NE_length), (j+1):(j+NE_length)), ncol = 2)\n    NE <- mat[mat_index]\n  }\n  \n  # South-East\n  SE_length <- min(to_S, to_E)\n  \n  if (i == nr | j == nc) SE <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SE_length), (j+1):(j+SE_length)), ncol = 2)\n    SE <- mat[mat_index]\n  }\n  \n  # South-West\n  SW_length <- min(to_S, to_W)\n  \n  if (i == nr | j == 1) SW <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SW_length), (j-1):(j-SW_length)), ncol = 2)\n    SW <- mat[mat_index]\n  }\n\n  # vectors from mat[i,j] to the edge in each direction \n  all_vecs <- \n    (list(N = N, S = S, E = E, W = W, NW = NW, NE = NE, SE = SE, SW = SW))\n  \n  # the first seat in each direction, collapsed to a vector\n  first_seats <- purrr::map_chr(all_vecs, get_first_seat_from_vec)\n  \n  # remove NAs from list and return\n  # (these occur either when starting on an edge, \n  # or when there are no seats in a given direction)\n  return(first_seats[!is.na(first_seats)])\n\n}\n\n\n\n\nToggle the code\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j, get_first_seat, 5))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_2_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 26\n\n\nOn the test set, this takes 6 iterations. On the full data set, my answer is 2128, and it took 87 iterations. Given this is fewer iterations than in Part 1, it must be my code for getting the first seat that’s slowing things down.\nI am unsatisfied both by how many lines of code this has taken as well as the time taken to run. The introduction to Advent of Code says that each challenge has a solution that will complete in at most 15 seconds on ten year old hardware. So clearly there’s a better way of doing this. Perhaps something to revisit in the future."
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#next",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#next",
    "title": "Advent of Code 2020",
    "section": "Next",
    "text": "Next\nI was late to the game, and that was as far as I managed to get in December 2020. I’m looking forward to taking on the challenge again in 2021!"
  },
  {
    "objectID": "posts/syntax-highlighting/index.html",
    "href": "posts/syntax-highlighting/index.html",
    "title": "Syntax Highlighting",
    "section": "",
    "text": "#| label: code-demo-py\n#| eval: false\n#| message: false\n#| warning: false\n\nimport numpy as np\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npenguins %>%\n  mutate(\n    long_flipper = case_when(\n      species == \"Adelie\" & flipper_length_mm > 195 ~ TRUE,\n      species == \"Chinstrap\" & flipper_length_mm > 200 ~ TRUE,\n      species == \"Gentoo\" & flipper_length_mm > 225 ~ TRUE,\n      TRUE ~ FALSE\n    )\n  )\n\n\"penguin\" == 5\n\nmy_var <- 218\n\nc(1,5,6) |> mean()\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by-sa/4.0/CitationBibTeX citation:@online{kaye2022,\n  author = {Ella Kaye and Ella Kaye},\n  title = {Syntax {Highlighting}},\n  date = {2022-07-29},\n  url = {https://ellakaye.rbind.io/posts/syntax-highlighting},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElla Kaye, and Ella Kaye. 2022. “Syntax Highlighting.” July\n29, 2022. https://ellakaye.rbind.io/posts/syntax-highlighting."
  },
  {
    "objectID": "posts/2017-06-17_n-letter-words/index.html",
    "href": "posts/2017-06-17_n-letter-words/index.html",
    "title": "n_letter_words and a personal (publicly available) package",
    "section": "",
    "text": "The function, n_letter_words, came about because I wanted to be able to generate row and column names for a large matrix - didn’t matter what they were, as long as they were unique. Since I was in the habit of using the built-in LETTERS vector to do this for small matrices, I naturally thought of using combinations of letters to do this in a larger case. In figuring out how to do this, as is so often the case, it was stackoverflow to the rescue. There, I learnt about expand.grid and could then use some tidyverse tools to get the vector I was after:\n\n\nToggle the code\nlibrary(tidyverse)\nout <- expand.grid(LETTERS, LETTERS) %>%\n  as_tibble() %>%\n  unite(word, 1:2, sep = \"\") %>%\n  pull()\nc(head(out), tail(out))\n\n\n [1] \"AA\" \"BA\" \"CA\" \"DA\" \"EA\" \"FA\" \"UZ\" \"VZ\" \"WZ\" \"XZ\" \"YZ\" \"ZZ\"\n\n\nSorted! At least I thought so, until, a couple of months later, when I wanted to generate names for a 1000*1000 matrix, and realised both that I’d forgotten the expand.grid trick, and once I’d re-found the stackoverflow post, that it didn’t give me enough words. That was enough to make it worth writing a function, taking n as an argument, that gives all ‘words’ of length \\(n\\).\nWriting functions always makes me think of what other arguments might be useful. What if we want something between the 676 two-letter words and 17,576 three-letter words (or the 456,976 four-letter words, etc)? Hence the argument num_letters, which can be set between 1 and 26, and results in a total of num_letters\\(^n\\) words. By default, the function returns a tibble, but setting as_vector = TRUE does what you’d expect. And I threw in a case argument too.\nNow that I had my function, what to do with it? I remembered articles I’d read about the usefulness of making and sharing a personal package. Now seemed like the time to do that myself.\nSo, here is my personal package, EMK. If you think that n_letter_words might be of use to you, then feel free to install!\n\n\nToggle the code\ndevtools::install_github(\"EllaKaye/EMK\")\n\n\nSome examples of n_letter_words:\n\n\nToggle the code\nlibrary(EMK)\n\nn_letter_words(2)\n\n\n# A tibble: 676 × 1\n   word \n   <chr>\n 1 AA   \n 2 BA   \n 3 CA   \n 4 DA   \n 5 EA   \n 6 FA   \n 7 GA   \n 8 HA   \n 9 IA   \n10 JA   \n# … with 666 more rows\n\n\nToggle the code\nsome_three_letter_words <- n_letter_words(\n  n = 3, \n  num_letters = 10, \n  case = \"lower\", \n  as_vector = TRUE\n)\n\nc(head(some_three_letter_words), tail(some_three_letter_words))\n\n\n [1] \"aaa\" \"baa\" \"caa\" \"daa\" \"eaa\" \"faa\" \"ejj\" \"fjj\" \"gjj\" \"hjj\" \"ijj\" \"jjj\"\n\n\nToggle the code\nlength(some_three_letter_words)\n\n\n[1] 1000\n\n\nFor now, my personal package has only this one function, but watch this space! No doubt I’ll be adding more that I find useful. Perhaps, you’ll find them useful too.\nIncidentally, none of the above would have happened if I’d just thought, for my test matrix A, to set dimnames(A) <- list(1:nrow(A), 1:ncol(A))!\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by-sa/4.0/CitationBibTeX citation:@online{kaye2017,\n  author = {Ella Kaye},\n  title = {N\\_letter\\_words and a Personal (Publicly Available) Package},\n  date = {2017-06-17},\n  url = {https://ellakaye.rbind.io/posts/2017-06-17_n-letter-words},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElla Kaye. 2017. “N_letter_words and a Personal (Publicly\nAvailable) Package.” June 17, 2017. https://ellakaye.rbind.io/posts/2017-06-17_n-letter-words."
  },
  {
    "objectID": "posts/icon-links/index.html",
    "href": "posts/icon-links/index.html",
    "title": "Experimenting with icon links",
    "section": "",
    "text": "Here an article: custom syntax highlighting for {distill}: modifying the theme."
  },
  {
    "objectID": "posts/icon-links/index.html#heres-some-code-in-h2",
    "href": "posts/icon-links/index.html#heres-some-code-in-h2",
    "title": "Experimenting with icon links",
    "section": "Here’s SOME code in h2",
    "text": "Here’s SOME code in h2\n\nHere’s SOME code in h3\n\nHere’s SOME code in h4\n\nHere’s SOME code in h5\n\nHere’s SOME code in h6\nThis is a post with executable code.\n\n\n[1] 2\n\n\nAdd bootstrap icons:\n  \nAdd fontawesome icons using the extension:\n \nCompare bi, fa ,"
  },
  {
    "objectID": "posts/icon-links/index.html#experimenting-with-distilltoolsicon_link-in-quarto",
    "href": "posts/icon-links/index.html#experimenting-with-distilltoolsicon_link-in-quarto",
    "title": "Experimenting with icon links",
    "section": "Experimenting with distilltools::icon_link in Quarto",
    "text": "Experimenting with distilltools::icon_link in Quarto\n\n\n\nIn a code block puts them all on separate lines.\n\n\n slides\n\n\n materials\n\n\n video\n\n\nBut using inline chunks gets them on the same line (as long as there are no line breaks between them):\n slides  materials  video\nalso, note, need display: inline-block in the css"
  },
  {
    "objectID": "posts/icon-links/index.html#using-btn-and-svg",
    "href": "posts/icon-links/index.html#using-btn-and-svg",
    "title": "Experimenting with icon links",
    "section": "Using btn and svg",
    "text": "Using btn and svg\n\n\n\n\nmaterials\n\n\n\n\n\nmaterials 2"
  },
  {
    "objectID": "posts/icon-links/index.html#using-btn-and-i",
    "href": "posts/icon-links/index.html#using-btn-and-i",
    "title": "Experimenting with icon links",
    "section": "Using btn and <i>",
    "text": "Using btn and <i>\n\n materials"
  },
  {
    "objectID": "posts/icon-links/index.html#conclusion",
    "href": "posts/icon-links/index.html#conclusion",
    "title": "Experimenting with icon links",
    "section": "Conclusion",
    "text": "Conclusion\nOriginal strategy, <a> styled to look like button, is probably best (see this StackOverflow).\nAlso, use <i> rather than <svg> as that’s what Quarto seems to do (though note can style <svg> with CSS).\nAlso, using font-size CSS property makes both icon and text bigger with <i> tag, but not <svg>."
  },
  {
    "objectID": "posts/icon-links/index.html#with-bigger-icon",
    "href": "posts/icon-links/index.html#with-bigger-icon",
    "title": "Experimenting with icon links",
    "section": "With bigger icon?",
    "text": "With bigger icon?\n slides"
  },
  {
    "objectID": "posts/icon-links/index.html#in-a-header",
    "href": "posts/icon-links/index.html#in-a-header",
    "title": "Experimenting with icon links",
    "section": "In a header",
    "text": "In a header\n\n materials"
  },
  {
    "objectID": "posts/icon-links/index.html#icon_link-html-with-bookstrap-icon",
    "href": "posts/icon-links/index.html#icon_link-html-with-bookstrap-icon",
    "title": "Experimenting with icon links",
    "section": "icon_link html with bookstrap icon:",
    "text": "icon_link html with bookstrap icon:\n slides"
  },
  {
    "objectID": "posts/icon-links/index.html#iconify",
    "href": "posts/icon-links/index.html#iconify",
    "title": "Experimenting with icon links",
    "section": "Iconify",
    "text": "Iconify"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "talks",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ELLA KAYE",
    "section": "",
    "text": "PLEASE SEE https://ellakaye.rbind.io FOR MY CURRENT SITE.\nHello and welcome to my personal website!\nI am a postgraduate researcher in Statistics at the University of Warwick and an R enthusiast."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "Ella Kaye\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTAG_1\n\n\nTAG_2\n\n\n\n\nPost description\n\n\n\n\n\n\nAug 5, 2022\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\nElla Kaye, Ella Kaye\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2022\n\n\nElla Kaye, Ella Kaye\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2022\n\n\nElla Kaye, Ella Kaye\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ndistill\n\n\ndistilltools\n\n\npackage development\n\n\n\n\nResources and sites I found inspiring when building my new site, and a sneak-peek at {distilltools}, an exciting new project for {distill} users\n\n\n\n\n\n\nMay 8, 2021\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nAdvent of Code\n\n\n\n\nMy attempts at Advent of Code, 2020\n\n\n\n\n\n\nDec 9, 2020\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\npackage development\n\n\n\n\nHow I created a handy function and a personal package\n\n\n\n\n\n\nJun 17, 2017\n\n\nElla Kaye\n\n\n\n\n\n\nNo matching items"
  }
]